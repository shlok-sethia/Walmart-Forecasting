{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport os, time, random","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#read the dataset prepared after feature engineering\ndata_path = 'data.csv'\ndata = pd.read_csv(data_path)\n\n#Understand the dataframe and datatypes for each column\nprint(data.info())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#remove columns which might lead to ordinal behavior\nremove_features = ['id','item_id','dept_id','cat_id','state_id','store_id', 'release',\n                   'event_name_1','event_type_1','event_name_2','event_type_2','event_name_1_lag_1',\n                   'event_type_1_lag_1', 'event_name_1_lag_2', 'event_type_1_lag_2',\n                   'event_name_1_lag_3', 'event_type_1_lag_3', 'date','wm_yr_wk','d',\n                   'sales','temp_d','day', 'week', 'month', 'year', 'dayofweek', 'weekend']","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Convert the object columns to datatype 'category'\ncategory_columns=['id','item_id','dept_id','cat_id','store_id','state_id','event_name_1','event_type_1','event_name_2','event_type_2','event_name_1_lag_1', 'event_type_1_lag_1',\n                   'event_name_1_lag_2', 'event_type_1_lag_2', 'event_name_1_lag_3', 'event_type_1_lag_3']\n\n#convert each category in the list one \nfor col in category_columns:\n    data[col] = data[col].astype('category')\n\n#Create a list of Store Ids for which data is considered \nstores_ids = data['store_id']\nstores_ids = list(stores_ids.unique())\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Check if it is indeed 'TX_1', since we choose this specific store for modeling purposes\n#due to processing power limitations and to avoid OOM(Out of Memory) Error\nstores_ids","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#copy the dataframe into new df\ndf = data.copy()\ndf","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Selected categorical columns are used for OneHotEnconding or to create DummyVariables/Columns\n#removes ordinal behavior\ndf = pd.get_dummies(data=df, columns=['cat_id', 'dept_id','event_name_1','event_name_2','day',\n 'week',\n 'month',\n 'year',\n 'dayofweek',\n 'weekend'])","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#create a temporary date column with integer values which denotes day number \n#this is later used for subsetting the data into test/train\ndf['temp_d'] = pd.to_numeric(data['d'].str[2:])\n\n#Once selected categorical columns are dummy encoded, \n#create list of categorical columns to remove from df \nfeatures = [col for col in list(df) if col not in remove_features]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Checking dummy encoded columns\ndf","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#List of features that we are finally considering for Modeling\nfeatures","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Creating variables for limiting the data by dates\nSTART_TRAIN = 1000      # Start day for training data\nEND_TRAIN   = 1885      # End day of our train data, \n#28 days after this are left for testing(1886 - Start day for Testing Data)  \nLimitData   = 1913      # End day for Testing Data\n    \n#Subset the data for 1000 to 1913 days\ndf = df[(df['temp_d']>=START_TRAIN) & (df['temp_d']<=LimitData)].reset_index(drop=True)\n#df = df[(df['temp_d']>=START_TRAIN)].reset_index(drop=True)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Create train and test datasets   \ntrain_mask = df['temp_d']<=END_TRAIN\n#valid_mask = train_mask&(df['temp_d']>(END_TRAIN-P_HORIZON))\npreds_mask = df['temp_d']>(END_TRAIN)\n\n\ntrain = df[train_mask.values]\ntest = df[preds_mask.values]\n\n#Split both train and test datasets for independant and depandant variables \nx_train = train[features]\ny_train = train[['sales']]\n\n\nx_test = test[features]\ny_test = test[['sales']]\n\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Fill the NAs with 0, if present\n\nx_test1 = x_test.fillna(0)\ny_test1 = y_test.fillna(0)\n\nx_train1 = x_train.fillna(0)\ny_train1 = y_train.fillna(0)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_test1","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Import the necessary libraries for - Linear Regression\nfrom sklearn import linear_model\nmodel = linear_model.LinearRegression()\n\n#Fit the model based on training data \nmodel.fit(x_train1,y_train1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#With the linear model built above, predict the sales for test timeframe\ntesting_predictions  = model.predict(x_test1)\ntesting_predictions","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Calculate the accuracy for linear regression\n\nfrom sklearn import metrics\nactuals = np.array(y_test1)\n\n#accuracy for train data\n\nlin_acc = model.score(x_train1,y_train1)\nprint(\"train accuracy\",lin_acc)\n\n\n#accuracy for test data\n\nlin_acc = model.score(x_test1,y_test1)\nprint(\"test accuracy\",lin_acc)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Import the Mean Squared Error and calculate RMSE\nfrom sklearn import metrics\nfrom sklearn.metrics import mean_squared_error\nprint(np.sqrt(mean_squared_error(y_test1, testing_predictions)))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}