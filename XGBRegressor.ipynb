{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport os, time, random","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"#Read the dataset prepared after feature engineering\ndata_path = 'data.csv'\ndata = pd.read_csv(data_path)\n\n#Understanding the dataframe and datatypes for each column\nprint(data.info())","metadata":{"trusted":true},"execution_count":2,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3166: DtypeWarning: Columns (11,12,13,14,16,17,18,19,20,21) have mixed types.Specify dtype option on import or set low_memory=False.\n  interactivity=interactivity, compiler=compiler, result=result)\n","output_type":"stream"},{"name":"stdout","text":"<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 4883327 entries, 0 to 4883326\nData columns (total 47 columns):\n #   Column              Dtype  \n---  ------              -----  \n 0   id                  object \n 1   item_id             object \n 2   dept_id             object \n 3   cat_id              object \n 4   store_id            object \n 5   state_id            object \n 6   d                   object \n 7   sales               float64\n 8   release             int64  \n 9   wm_yr_wk            int64  \n 10  date                object \n 11  event_name_1        object \n 12  event_type_1        object \n 13  event_name_2        object \n 14  event_type_2        object \n 15  snap_TX             int64  \n 16  event_name_1_lag_1  object \n 17  event_type_1_lag_1  object \n 18  event_name_1_lag_2  object \n 19  event_type_1_lag_2  object \n 20  event_name_1_lag_3  object \n 21  event_type_1_lag_3  object \n 22  snap_TX_lag_1       float64\n 23  snap_TX_lag_2       float64\n 24  snap_TX_lag_3       float64\n 25  day                 int64  \n 26  week                int64  \n 27  month               int64  \n 28  year                int64  \n 29  dayofweek           int64  \n 30  weekend             int64  \n 31  lag_28              float64\n 32  lag_29              float64\n 33  lag_30              float64\n 34  lag_31              float64\n 35  lag_32              float64\n 36  lag_33              float64\n 37  lag_34              float64\n 38  lag_35              float64\n 39  rolling_mean_7      float64\n 40  rolling_std_7       float64\n 41  rolling_mean_14     float64\n 42  rolling_std_14      float64\n 43  rolling_mean_30     float64\n 44  rolling_std_30      float64\n 45  rolling_mean_60     float64\n 46  rolling_std_60      float64\ndtypes: float64(20), int64(9), object(18)\nmemory usage: 1.7+ GB\nNone\n","output_type":"stream"}]},{"cell_type":"code","source":"#remove columns which might lead to ordinal behavior\n\nremove_features = ['id','item_id','dept_id','cat_id','state_id','store_id', 'release', 'event_name_1','event_type_1','event_name_2','event_type_2','event_name_1_lag_1', 'event_type_1_lag_1',\n                   'event_name_1_lag_2', 'event_type_1_lag_2', 'event_name_1_lag_3', 'event_type_1_lag_3',\n                   'date','wm_yr_wk','d','sales','temp_d','day', 'week', 'month', 'year', 'dayofweek', 'weekend']","metadata":{"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"#Convert the object columns to datatype 'category'\ncategory_columns=['id','item_id','dept_id','cat_id','store_id','state_id','event_name_1','event_type_1','event_name_2','event_type_2','event_name_1_lag_1', 'event_type_1_lag_1',\n                   'event_name_1_lag_2', 'event_type_1_lag_2', 'event_name_1_lag_3', 'event_type_1_lag_3']\n\n#Convert each category in the list one \nfor col in category_columns:\n    data[col] = data[col].astype('category')\n\n#Create a list of Store Ids for which data is considered \nstores_ids = data['store_id']\nstores_ids = list(stores_ids.unique())\n","metadata":{"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"#Check if it is indeed 'TX_1', since we choose this specific store for modeling purposes\n#due to processing power limitations and to avoid OOM(Out of Memory) Error \nstores_ids","metadata":{"trusted":true},"execution_count":5,"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"['TX_1']"},"metadata":{}}]},{"cell_type":"code","source":"#copy the dataframe into new df\ndf = data.copy()\ndf","metadata":{"trusted":true},"execution_count":6,"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"                                    id        item_id    dept_id   cat_id  \\\n0        HOBBIES_1_004_TX_1_evaluation  HOBBIES_1_004  HOBBIES_1  HOBBIES   \n1        HOBBIES_1_008_TX_1_evaluation  HOBBIES_1_008  HOBBIES_1  HOBBIES   \n2        HOBBIES_1_009_TX_1_evaluation  HOBBIES_1_009  HOBBIES_1  HOBBIES   \n3        HOBBIES_1_010_TX_1_evaluation  HOBBIES_1_010  HOBBIES_1  HOBBIES   \n4        HOBBIES_1_012_TX_1_evaluation  HOBBIES_1_012  HOBBIES_1  HOBBIES   \n...                                ...            ...        ...      ...   \n4883322    FOODS_3_823_TX_1_evaluation    FOODS_3_823    FOODS_3    FOODS   \n4883323    FOODS_3_824_TX_1_evaluation    FOODS_3_824    FOODS_3    FOODS   \n4883324    FOODS_3_825_TX_1_evaluation    FOODS_3_825    FOODS_3    FOODS   \n4883325    FOODS_3_826_TX_1_evaluation    FOODS_3_826    FOODS_3    FOODS   \n4883326    FOODS_3_827_TX_1_evaluation    FOODS_3_827    FOODS_3    FOODS   \n\n        store_id state_id       d  sales  release  wm_yr_wk  ... lag_34  \\\n0           TX_1       TX     d_1    1.0    11101     11101  ...    NaN   \n1           TX_1       TX     d_1    4.0    11101     11101  ...    NaN   \n2           TX_1       TX     d_1    3.0    11101     11101  ...    NaN   \n3           TX_1       TX     d_1    0.0    11101     11101  ...    NaN   \n4           TX_1       TX     d_1    0.0    11101     11101  ...    NaN   \n...          ...      ...     ...    ...      ...       ...  ...    ...   \n4883322     TX_1       TX  d_1941    NaN    11101     11617  ...    0.0   \n4883323     TX_1       TX  d_1941    NaN    11101     11617  ...    0.0   \n4883324     TX_1       TX  d_1941    NaN    11101     11617  ...    1.0   \n4883325     TX_1       TX  d_1941    NaN    11312     11617  ...    0.0   \n4883326     TX_1       TX  d_1941    NaN    11407     11617  ...    3.0   \n\n        lag_35 rolling_mean_7 rolling_std_7 rolling_mean_14  rolling_std_14  \\\n0          NaN            NaN           NaN             NaN             NaN   \n1          NaN            NaN           NaN             NaN             NaN   \n2          NaN            NaN           NaN             NaN             NaN   \n3          NaN            NaN           NaN             NaN             NaN   \n4          NaN            NaN           NaN             NaN             NaN   \n...        ...            ...           ...             ...             ...   \n4883322    0.0         0.4285        0.5347          0.5000          0.6504   \n4883323    0.0         0.0000        0.0000          0.0000          0.0000   \n4883324    2.0         0.5713        0.5347          0.9287          0.8286   \n4883325    0.0         0.4285        0.5347          0.5713          0.6460   \n4883326    0.0         1.8570        2.2680          1.1430          1.7480   \n\n        rolling_mean_30 rolling_std_30 rolling_mean_60 rolling_std_60  \n0                   NaN            NaN             NaN            NaN  \n1                   NaN            NaN             NaN            NaN  \n2                   NaN            NaN             NaN            NaN  \n3                   NaN            NaN             NaN            NaN  \n4                   NaN            NaN             NaN            NaN  \n...                 ...            ...             ...            ...  \n4883322         0.56700         0.6260          0.3167         0.5366  \n4883323         0.03333         0.1826          0.0500         0.2197  \n4883324         0.53300         0.7760          0.4666         0.7240  \n4883325         0.83350         0.9497          0.7666         0.9272  \n4883326         1.13400         1.5920          1.4000         2.0760  \n\n[4883327 rows x 47 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>item_id</th>\n      <th>dept_id</th>\n      <th>cat_id</th>\n      <th>store_id</th>\n      <th>state_id</th>\n      <th>d</th>\n      <th>sales</th>\n      <th>release</th>\n      <th>wm_yr_wk</th>\n      <th>...</th>\n      <th>lag_34</th>\n      <th>lag_35</th>\n      <th>rolling_mean_7</th>\n      <th>rolling_std_7</th>\n      <th>rolling_mean_14</th>\n      <th>rolling_std_14</th>\n      <th>rolling_mean_30</th>\n      <th>rolling_std_30</th>\n      <th>rolling_mean_60</th>\n      <th>rolling_std_60</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>HOBBIES_1_004_TX_1_evaluation</td>\n      <td>HOBBIES_1_004</td>\n      <td>HOBBIES_1</td>\n      <td>HOBBIES</td>\n      <td>TX_1</td>\n      <td>TX</td>\n      <td>d_1</td>\n      <td>1.0</td>\n      <td>11101</td>\n      <td>11101</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>HOBBIES_1_008_TX_1_evaluation</td>\n      <td>HOBBIES_1_008</td>\n      <td>HOBBIES_1</td>\n      <td>HOBBIES</td>\n      <td>TX_1</td>\n      <td>TX</td>\n      <td>d_1</td>\n      <td>4.0</td>\n      <td>11101</td>\n      <td>11101</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>HOBBIES_1_009_TX_1_evaluation</td>\n      <td>HOBBIES_1_009</td>\n      <td>HOBBIES_1</td>\n      <td>HOBBIES</td>\n      <td>TX_1</td>\n      <td>TX</td>\n      <td>d_1</td>\n      <td>3.0</td>\n      <td>11101</td>\n      <td>11101</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>HOBBIES_1_010_TX_1_evaluation</td>\n      <td>HOBBIES_1_010</td>\n      <td>HOBBIES_1</td>\n      <td>HOBBIES</td>\n      <td>TX_1</td>\n      <td>TX</td>\n      <td>d_1</td>\n      <td>0.0</td>\n      <td>11101</td>\n      <td>11101</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>HOBBIES_1_012_TX_1_evaluation</td>\n      <td>HOBBIES_1_012</td>\n      <td>HOBBIES_1</td>\n      <td>HOBBIES</td>\n      <td>TX_1</td>\n      <td>TX</td>\n      <td>d_1</td>\n      <td>0.0</td>\n      <td>11101</td>\n      <td>11101</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>4883322</th>\n      <td>FOODS_3_823_TX_1_evaluation</td>\n      <td>FOODS_3_823</td>\n      <td>FOODS_3</td>\n      <td>FOODS</td>\n      <td>TX_1</td>\n      <td>TX</td>\n      <td>d_1941</td>\n      <td>NaN</td>\n      <td>11101</td>\n      <td>11617</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.4285</td>\n      <td>0.5347</td>\n      <td>0.5000</td>\n      <td>0.6504</td>\n      <td>0.56700</td>\n      <td>0.6260</td>\n      <td>0.3167</td>\n      <td>0.5366</td>\n    </tr>\n    <tr>\n      <th>4883323</th>\n      <td>FOODS_3_824_TX_1_evaluation</td>\n      <td>FOODS_3_824</td>\n      <td>FOODS_3</td>\n      <td>FOODS</td>\n      <td>TX_1</td>\n      <td>TX</td>\n      <td>d_1941</td>\n      <td>NaN</td>\n      <td>11101</td>\n      <td>11617</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0000</td>\n      <td>0.0000</td>\n      <td>0.0000</td>\n      <td>0.0000</td>\n      <td>0.03333</td>\n      <td>0.1826</td>\n      <td>0.0500</td>\n      <td>0.2197</td>\n    </tr>\n    <tr>\n      <th>4883324</th>\n      <td>FOODS_3_825_TX_1_evaluation</td>\n      <td>FOODS_3_825</td>\n      <td>FOODS_3</td>\n      <td>FOODS</td>\n      <td>TX_1</td>\n      <td>TX</td>\n      <td>d_1941</td>\n      <td>NaN</td>\n      <td>11101</td>\n      <td>11617</td>\n      <td>...</td>\n      <td>1.0</td>\n      <td>2.0</td>\n      <td>0.5713</td>\n      <td>0.5347</td>\n      <td>0.9287</td>\n      <td>0.8286</td>\n      <td>0.53300</td>\n      <td>0.7760</td>\n      <td>0.4666</td>\n      <td>0.7240</td>\n    </tr>\n    <tr>\n      <th>4883325</th>\n      <td>FOODS_3_826_TX_1_evaluation</td>\n      <td>FOODS_3_826</td>\n      <td>FOODS_3</td>\n      <td>FOODS</td>\n      <td>TX_1</td>\n      <td>TX</td>\n      <td>d_1941</td>\n      <td>NaN</td>\n      <td>11312</td>\n      <td>11617</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.4285</td>\n      <td>0.5347</td>\n      <td>0.5713</td>\n      <td>0.6460</td>\n      <td>0.83350</td>\n      <td>0.9497</td>\n      <td>0.7666</td>\n      <td>0.9272</td>\n    </tr>\n    <tr>\n      <th>4883326</th>\n      <td>FOODS_3_827_TX_1_evaluation</td>\n      <td>FOODS_3_827</td>\n      <td>FOODS_3</td>\n      <td>FOODS</td>\n      <td>TX_1</td>\n      <td>TX</td>\n      <td>d_1941</td>\n      <td>NaN</td>\n      <td>11407</td>\n      <td>11617</td>\n      <td>...</td>\n      <td>3.0</td>\n      <td>0.0</td>\n      <td>1.8570</td>\n      <td>2.2680</td>\n      <td>1.1430</td>\n      <td>1.7480</td>\n      <td>1.13400</td>\n      <td>1.5920</td>\n      <td>1.4000</td>\n      <td>2.0760</td>\n    </tr>\n  </tbody>\n</table>\n<p>4883327 rows × 47 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"#Selected categorical columns are used for OneHotEnconding or to create DummyVariables/Columns\n#removes ordinal behavior  \ndf = pd.get_dummies(data=df, columns=['dept_id','event_name_1','event_name_2','day',\n 'week',\n 'month',\n 'year',\n 'dayofweek',\n 'weekend'])\n\n#create a temporary date column with integer values which denotes day number \n#this is later used for subsetting the data into test/train\ndf['temp_d'] = pd.to_numeric(data['d'].str[2:])\n\n#Once selected categorical columns are dummy encoded, \n#create list of categorical columns to remove from df \nfeatures = [col for col in list(df) if col not in remove_features]","metadata":{"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"#Checking dummy encoded columns\ndf","metadata":{"trusted":true},"execution_count":8,"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"                                    id        item_id   cat_id store_id  \\\n0        HOBBIES_1_004_TX_1_evaluation  HOBBIES_1_004  HOBBIES     TX_1   \n1        HOBBIES_1_008_TX_1_evaluation  HOBBIES_1_008  HOBBIES     TX_1   \n2        HOBBIES_1_009_TX_1_evaluation  HOBBIES_1_009  HOBBIES     TX_1   \n3        HOBBIES_1_010_TX_1_evaluation  HOBBIES_1_010  HOBBIES     TX_1   \n4        HOBBIES_1_012_TX_1_evaluation  HOBBIES_1_012  HOBBIES     TX_1   \n...                                ...            ...      ...      ...   \n4883322    FOODS_3_823_TX_1_evaluation    FOODS_3_823    FOODS     TX_1   \n4883323    FOODS_3_824_TX_1_evaluation    FOODS_3_824    FOODS     TX_1   \n4883324    FOODS_3_825_TX_1_evaluation    FOODS_3_825    FOODS     TX_1   \n4883325    FOODS_3_826_TX_1_evaluation    FOODS_3_826    FOODS     TX_1   \n4883326    FOODS_3_827_TX_1_evaluation    FOODS_3_827    FOODS     TX_1   \n\n        state_id       d  sales  release  wm_yr_wk        date  ...  \\\n0             TX     d_1    1.0    11101     11101  2011-01-29  ...   \n1             TX     d_1    4.0    11101     11101  2011-01-29  ...   \n2             TX     d_1    3.0    11101     11101  2011-01-29  ...   \n3             TX     d_1    0.0    11101     11101  2011-01-29  ...   \n4             TX     d_1    0.0    11101     11101  2011-01-29  ...   \n...          ...     ...    ...      ...       ...         ...  ...   \n4883322       TX  d_1941    NaN    11101     11617  2016-05-22  ...   \n4883323       TX  d_1941    NaN    11101     11617  2016-05-22  ...   \n4883324       TX  d_1941    NaN    11101     11617  2016-05-22  ...   \n4883325       TX  d_1941    NaN    11312     11617  2016-05-22  ...   \n4883326       TX  d_1941    NaN    11407     11617  2016-05-22  ...   \n\n        dayofweek_0 dayofweek_1  dayofweek_2 dayofweek_3 dayofweek_4  \\\n0                 0           0            0           0           0   \n1                 0           0            0           0           0   \n2                 0           0            0           0           0   \n3                 0           0            0           0           0   \n4                 0           0            0           0           0   \n...             ...         ...          ...         ...         ...   \n4883322           0           0            0           0           0   \n4883323           0           0            0           0           0   \n4883324           0           0            0           0           0   \n4883325           0           0            0           0           0   \n4883326           0           0            0           0           0   \n\n        dayofweek_5 dayofweek_6 weekend_0 weekend_1  temp_d  \n0                 1           0         0         1       1  \n1                 1           0         0         1       1  \n2                 1           0         0         1       1  \n3                 1           0         0         1       1  \n4                 1           0         0         1       1  \n...             ...         ...       ...       ...     ...  \n4883322           0           1         0         1    1941  \n4883323           0           1         0         1    1941  \n4883324           0           1         0         1    1941  \n4883325           0           1         0         1    1941  \n4883326           0           1         0         1    1941  \n\n[4883327 rows x 191 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>item_id</th>\n      <th>cat_id</th>\n      <th>store_id</th>\n      <th>state_id</th>\n      <th>d</th>\n      <th>sales</th>\n      <th>release</th>\n      <th>wm_yr_wk</th>\n      <th>date</th>\n      <th>...</th>\n      <th>dayofweek_0</th>\n      <th>dayofweek_1</th>\n      <th>dayofweek_2</th>\n      <th>dayofweek_3</th>\n      <th>dayofweek_4</th>\n      <th>dayofweek_5</th>\n      <th>dayofweek_6</th>\n      <th>weekend_0</th>\n      <th>weekend_1</th>\n      <th>temp_d</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>HOBBIES_1_004_TX_1_evaluation</td>\n      <td>HOBBIES_1_004</td>\n      <td>HOBBIES</td>\n      <td>TX_1</td>\n      <td>TX</td>\n      <td>d_1</td>\n      <td>1.0</td>\n      <td>11101</td>\n      <td>11101</td>\n      <td>2011-01-29</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>HOBBIES_1_008_TX_1_evaluation</td>\n      <td>HOBBIES_1_008</td>\n      <td>HOBBIES</td>\n      <td>TX_1</td>\n      <td>TX</td>\n      <td>d_1</td>\n      <td>4.0</td>\n      <td>11101</td>\n      <td>11101</td>\n      <td>2011-01-29</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>HOBBIES_1_009_TX_1_evaluation</td>\n      <td>HOBBIES_1_009</td>\n      <td>HOBBIES</td>\n      <td>TX_1</td>\n      <td>TX</td>\n      <td>d_1</td>\n      <td>3.0</td>\n      <td>11101</td>\n      <td>11101</td>\n      <td>2011-01-29</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>HOBBIES_1_010_TX_1_evaluation</td>\n      <td>HOBBIES_1_010</td>\n      <td>HOBBIES</td>\n      <td>TX_1</td>\n      <td>TX</td>\n      <td>d_1</td>\n      <td>0.0</td>\n      <td>11101</td>\n      <td>11101</td>\n      <td>2011-01-29</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>HOBBIES_1_012_TX_1_evaluation</td>\n      <td>HOBBIES_1_012</td>\n      <td>HOBBIES</td>\n      <td>TX_1</td>\n      <td>TX</td>\n      <td>d_1</td>\n      <td>0.0</td>\n      <td>11101</td>\n      <td>11101</td>\n      <td>2011-01-29</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>4883322</th>\n      <td>FOODS_3_823_TX_1_evaluation</td>\n      <td>FOODS_3_823</td>\n      <td>FOODS</td>\n      <td>TX_1</td>\n      <td>TX</td>\n      <td>d_1941</td>\n      <td>NaN</td>\n      <td>11101</td>\n      <td>11617</td>\n      <td>2016-05-22</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1941</td>\n    </tr>\n    <tr>\n      <th>4883323</th>\n      <td>FOODS_3_824_TX_1_evaluation</td>\n      <td>FOODS_3_824</td>\n      <td>FOODS</td>\n      <td>TX_1</td>\n      <td>TX</td>\n      <td>d_1941</td>\n      <td>NaN</td>\n      <td>11101</td>\n      <td>11617</td>\n      <td>2016-05-22</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1941</td>\n    </tr>\n    <tr>\n      <th>4883324</th>\n      <td>FOODS_3_825_TX_1_evaluation</td>\n      <td>FOODS_3_825</td>\n      <td>FOODS</td>\n      <td>TX_1</td>\n      <td>TX</td>\n      <td>d_1941</td>\n      <td>NaN</td>\n      <td>11101</td>\n      <td>11617</td>\n      <td>2016-05-22</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1941</td>\n    </tr>\n    <tr>\n      <th>4883325</th>\n      <td>FOODS_3_826_TX_1_evaluation</td>\n      <td>FOODS_3_826</td>\n      <td>FOODS</td>\n      <td>TX_1</td>\n      <td>TX</td>\n      <td>d_1941</td>\n      <td>NaN</td>\n      <td>11312</td>\n      <td>11617</td>\n      <td>2016-05-22</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1941</td>\n    </tr>\n    <tr>\n      <th>4883326</th>\n      <td>FOODS_3_827_TX_1_evaluation</td>\n      <td>FOODS_3_827</td>\n      <td>FOODS</td>\n      <td>TX_1</td>\n      <td>TX</td>\n      <td>d_1941</td>\n      <td>NaN</td>\n      <td>11407</td>\n      <td>11617</td>\n      <td>2016-05-22</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1941</td>\n    </tr>\n  </tbody>\n</table>\n<p>4883327 rows × 191 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"#List of features that we are finally considering for Modeling\nfeatures","metadata":{"trusted":true},"execution_count":9,"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"['snap_TX',\n 'snap_TX_lag_1',\n 'snap_TX_lag_2',\n 'snap_TX_lag_3',\n 'lag_28',\n 'lag_29',\n 'lag_30',\n 'lag_31',\n 'lag_32',\n 'lag_33',\n 'lag_34',\n 'lag_35',\n 'rolling_mean_7',\n 'rolling_std_7',\n 'rolling_mean_14',\n 'rolling_std_14',\n 'rolling_mean_30',\n 'rolling_std_30',\n 'rolling_mean_60',\n 'rolling_std_60',\n 'dept_id_FOODS_1',\n 'dept_id_FOODS_2',\n 'dept_id_FOODS_3',\n 'dept_id_HOBBIES_1',\n 'dept_id_HOBBIES_2',\n 'dept_id_HOUSEHOLD_1',\n 'dept_id_HOUSEHOLD_2',\n 'event_name_1_Chanukah End',\n 'event_name_1_Christmas',\n 'event_name_1_Cinco De Mayo',\n 'event_name_1_ColumbusDay',\n 'event_name_1_Easter',\n 'event_name_1_Eid al-Fitr',\n 'event_name_1_EidAlAdha',\n \"event_name_1_Father's day\",\n 'event_name_1_Halloween',\n 'event_name_1_IndependenceDay',\n 'event_name_1_LaborDay',\n 'event_name_1_LentStart',\n 'event_name_1_LentWeek2',\n 'event_name_1_MartinLutherKingDay',\n 'event_name_1_MemorialDay',\n \"event_name_1_Mother's day\",\n 'event_name_1_NBAFinalsEnd',\n 'event_name_1_NBAFinalsStart',\n 'event_name_1_NewYear',\n 'event_name_1_OrthodoxChristmas',\n 'event_name_1_OrthodoxEaster',\n 'event_name_1_Pesach End',\n 'event_name_1_PresidentsDay',\n 'event_name_1_Purim End',\n 'event_name_1_Ramadan starts',\n 'event_name_1_StPatricksDay',\n 'event_name_1_SuperBowl',\n 'event_name_1_Thanksgiving',\n 'event_name_1_ValentinesDay',\n 'event_name_1_VeteransDay',\n 'event_name_2_Cinco De Mayo',\n 'event_name_2_Easter',\n \"event_name_2_Father's day\",\n 'event_name_2_OrthodoxEaster',\n 'day_1',\n 'day_2',\n 'day_3',\n 'day_4',\n 'day_5',\n 'day_6',\n 'day_7',\n 'day_8',\n 'day_9',\n 'day_10',\n 'day_11',\n 'day_12',\n 'day_13',\n 'day_14',\n 'day_15',\n 'day_16',\n 'day_17',\n 'day_18',\n 'day_19',\n 'day_20',\n 'day_21',\n 'day_22',\n 'day_23',\n 'day_24',\n 'day_25',\n 'day_26',\n 'day_27',\n 'day_28',\n 'day_29',\n 'day_30',\n 'day_31',\n 'week_1',\n 'week_2',\n 'week_3',\n 'week_4',\n 'week_5',\n 'week_6',\n 'week_7',\n 'week_8',\n 'week_9',\n 'week_10',\n 'week_11',\n 'week_12',\n 'week_13',\n 'week_14',\n 'week_15',\n 'week_16',\n 'week_17',\n 'week_18',\n 'week_19',\n 'week_20',\n 'week_21',\n 'week_22',\n 'week_23',\n 'week_24',\n 'week_25',\n 'week_26',\n 'week_27',\n 'week_28',\n 'week_29',\n 'week_30',\n 'week_31',\n 'week_32',\n 'week_33',\n 'week_34',\n 'week_35',\n 'week_36',\n 'week_37',\n 'week_38',\n 'week_39',\n 'week_40',\n 'week_41',\n 'week_42',\n 'week_43',\n 'week_44',\n 'week_45',\n 'week_46',\n 'week_47',\n 'week_48',\n 'week_49',\n 'week_50',\n 'week_51',\n 'week_52',\n 'week_53',\n 'month_1',\n 'month_2',\n 'month_3',\n 'month_4',\n 'month_5',\n 'month_6',\n 'month_7',\n 'month_8',\n 'month_9',\n 'month_10',\n 'month_11',\n 'month_12',\n 'year_0',\n 'year_1',\n 'year_2',\n 'year_3',\n 'year_4',\n 'year_5',\n 'dayofweek_0',\n 'dayofweek_1',\n 'dayofweek_2',\n 'dayofweek_3',\n 'dayofweek_4',\n 'dayofweek_5',\n 'dayofweek_6',\n 'weekend_0',\n 'weekend_1']"},"metadata":{}}]},{"cell_type":"code","source":"#Creating variables for limiting the data by dates\nSTART_TRAIN = 1000                # Start day for training data\nEND_TRAIN   = 1885               # End day of our train set, 28 days after this are left for testing(Start day for Testing Data)  \nLimitData   = 1913              # End day for Testing Data\n    \n#Subset the data for 1000 to 1913 days\ndf = df[(df['temp_d']>=START_TRAIN) & (df['temp_d']<=LimitData)].reset_index(drop=True)\n\n#df = df[(df['temp_d']>=START_TRAIN)].reset_index(drop=True)\n","metadata":{"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"#Create train and test datasets   \ntrain_mask = df['temp_d']<=END_TRAIN\n#valid_mask = train_mask&(df['temp_d']>(END_TRAIN-P_HORIZON))\npreds_mask = df['temp_d']>(END_TRAIN)\n\n\ntrain = df[train_mask.values]\ntest = df[preds_mask.values]\n\n#Split both train and test datasets for independant and depandant variables \nx_train = train[features]\ny_train = train[['sales']]\n\n\nx_test = test[features]\ny_test = test[['sales']]\n\n","metadata":{"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"#Fill the NAs with 0, if present\n\nx_test1 = x_test\ny_test1 = y_test\n\nx_train1 = x_train\ny_train1 = y_train","metadata":{"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"y_test1","metadata":{"trusted":true},"execution_count":13,"outputs":[{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"         sales\n2597874    1.0\n2597875    0.0\n2597876    0.0\n2597877    0.0\n2597878    0.0\n...        ...\n2683241    0.0\n2683242    0.0\n2683243    0.0\n2683244    0.0\n2683245    0.0\n\n[85372 rows x 1 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>sales</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>2597874</th>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>2597875</th>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2597876</th>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2597877</th>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2597878</th>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>2683241</th>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2683242</th>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2683243</th>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2683244</th>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2683245</th>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>85372 rows × 1 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"##Import the necessary libraries for - XG Boost\n\nimport xgboost as xgb\n\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.metrics import mean_absolute_error\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\n\n\nx_model = xgb.XGBRegressor(\n learning_rate =0.09,\n n_estimators=1200,\n max_depth=4,\n min_child_weight=3,\n gamma=0,\n subsample=0.8,\n reg_alpha=200, reg_lambda=200,\n colsample_bytree=0.8,nthread=4)\n\n#Fit the model based on training data \nx_model.fit(x_train1,y_train1)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Import the Mean Squared Error to eventually calculate the RMSE\n\nfrom sklearn.metrics import mean_squared_error as MSE\npred = x_model.predict(x_test1)\nrmse = np.sqrt(MSE(y_test1, pred))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"rmse","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}